Got it âœ… â€” hereâ€™s a clean **README.md** for your project:

---

# ğŸ¦ Website Cloner CLI (GenAI + OpenAI + Puppeteer)

A command-line tool that uses **OpenAI GPT**, **Puppeteer**, and **Node.js** to scrape and clone websites into fully working HTML/CSS/JS projects.
The assistant follows a **step-by-step reasoning loop** (START â†’ THINK â†’ TOOL â†’ OBSERVE â†’ OUTPUT) to analyze, scrape, and generate a website clone.

---

## ğŸš€ Features

* Scrapes target websites with **Puppeteer**
* Generates **static clones** using HTML, CSS, and JavaScript
* Writes project files automatically (`index.html`, `styles.css`, `script.js`)
* Uses **OpenAI GPT** to plan and structure the clone
* Modular **TOOL system** (`scrape_website`, `CODE`)
* Strict **JSON-driven workflow** for reproducibility

---

## ğŸ“‚ Project Structure

When cloning a site, the tool creates a new folder:

```
project_name/
 â”œâ”€â”€ index.html
 â”œâ”€â”€ styles.css
 â””â”€â”€ script.js
```

---

## âš™ï¸ Installation

### 1. Clone the repo

```bash
git clone https://github.com/your-username/website-cloner-cli.git
cd website-cloner-cli
```

### 2. Install dependencies

```bash
npm install
```

### 3. Setup environment

Create a `.env` file in the root:

```
OPENAI_API_KEY=your_openai_api_key
```

---

## â–¶ï¸ Usage

Run the CLI with a target URL:

```bash
node index.js https://www.netflix.com/browse
```

Example output:

```
ğŸ”¥ User wants to clone Netflix browse page: https://www.netflix.com/browse
ğŸ› ï¸: scrape_website(...) = content retrieved
ğŸ§  Plan: create project folder and HTML/CSS/JS files
ğŸ› ï¸: CODE(mkdir project) = âœ… folder created
ğŸ› ï¸: CODE(filepath:index.html) = âœ… file written
ğŸ¤– Clone ready at ./project
```

Open the generated `index.html` in your browser ğŸ‰

---

## ğŸ› ï¸ Available Tools

* **scrape\_website(url: string)** â†’ extracts content and layout from a website
* **CODE(input: string)** â†’ executes shell commands (e.g., `mkdir`, `ni`)
* **CODE(filepath: string, data: string)** â†’ writes content directly to a file

---

## ğŸ“œ Workflow

The AI assistant strictly follows this loop:

1. **START** â†’ Acknowledge user request
2. **THINK** â†’ Plan steps
3. **TOOL** â†’ Call available tools (`scrape_website`, `CODE`)
4. **OBSERVE** â†’ Developer logs result of tool execution
5. **OUTPUT** â†’ Confirm project clone is ready

---

## ğŸ”‘ Example JSON Flow

```json
{"step":"START","content":"User wants to clone https://www.google.com"}
{"step":"THINK","content":"I should scrape the website to analyze its layout"}
{"step":"TOOL","tool_name":"scrape_website","input":"https://www.google.com"}
{"step":"THINK","content":"Now I will create a new project folder"}
{"step":"TOOL","tool_name":"CODE","input":"mkdir google_clone"}
{"step":"TOOL","tool_name":"CODE","filepath":"google_clone/index.html","data":"<html>...</html>"}
{"step":"OUTPUT","content":"Clone created in ./google_clone"}
```

---

## ğŸ“Œ Requirements

* Node.js 18+
* OpenAI API key
* Internet connection for scraping

---

